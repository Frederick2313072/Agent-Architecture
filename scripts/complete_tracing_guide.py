#!/usr/bin/env python3
"""
å®Œæ•´çš„ Agent ç³»ç»Ÿ Tracing æŒ‡å—
æ¼”ç¤ºå¦‚ä½•åœ¨å„ä¸ªå±‚é¢è¿›è¡Œè¿½è¸ªå’Œå¯è§‚æµ‹æ€§
"""

import asyncio
import time
from datetime import datetime
from typing import Dict, Any, List
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.progress import Progress
from src.observability import ObservabilityManager, traced_agent_operation, log_conversation
from src.safety import SafetyManager, ValidationStatus
from src.config import config

console = Console()

class TracingDemoAgent:
    """æ¼”ç¤º Tracing åŠŸèƒ½çš„ç¤ºä¾‹ Agent"""
    
    def __init__(self, name: str):
        self.name = name
        self.obs_manager = ObservabilityManager()
        self.safety_manager = SafetyManager()
        
    @traced_agent_operation("agent_initialization")
    def initialize(self):
        """åˆå§‹åŒ– Agent"""
        console.print(f"ğŸ¤– [blue]åˆå§‹åŒ– Agent: {self.name}[/blue]")
        self.obs_manager.initialize()
        return f"Agent {self.name} åˆå§‹åŒ–å®Œæˆ"
    
    @traced_agent_operation("agent_thinking")
    def think(self, input_message: str) -> Dict[str, Any]:
        """Agent æ€è€ƒè¿‡ç¨‹"""
        console.print(f"ğŸ§  [yellow]{self.name} æ­£åœ¨æ€è€ƒ: {input_message[:50]}...[/yellow]")
        
        # æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´
        time.sleep(0.5)
        
        thought_process = {
            "original_input": input_message,
            "analysis": f"åˆ†æè¾“å…¥å†…å®¹çš„ä¸»è¦æ„å›¾å’Œå…³é”®è¯",
            "strategy": "é€‰æ‹©æœ€é€‚åˆçš„å›åº”ç­–ç•¥",
            "confidence": 0.85,
            "reasoning_steps": [
                "1. è§£æç”¨æˆ·æ„å›¾",
                "2. æ£€ç´¢ç›¸å…³çŸ¥è¯†",
                "3. æ„å»ºå›åº”æ¡†æ¶",
                "4. ä¼˜åŒ–è¡¨è¾¾æ–¹å¼"
            ]
        }
        
        return thought_process
    
    @traced_agent_operation("agent_generate_reply")
    async def generate_reply(self, messages: List[Dict], context: Dict = None) -> str:
        """ç”Ÿæˆå›å¤ - åŒ…å«å®Œæ•´çš„ tracing"""
        console.print(f"ğŸ’¬ [green]{self.name} æ­£åœ¨ç”Ÿæˆå›å¤...[/green]")
        
        # è®°å½•å¯¹è¯åˆ°è¿½è¸ªç³»ç»Ÿ
        log_conversation(
            agent_name=self.name,
            message=str(messages),
            role="user",
            metadata={"context": context or {}}
        )
        
        # 1. å®‰å…¨æ£€æŸ¥
        input_content = messages[-1].get("content", "") if messages else ""
        safety_result = await self.safety_manager.moderate_content(input_content)
        
        if safety_result.flagged:
            console.print(f"âš ï¸ [red]å†…å®¹è¢«å®‰å…¨æ£€æŸ¥æ ‡è®°: {safety_result.reason}[/red]")
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚"
        
        # 2. æ€è€ƒè¿‡ç¨‹
        thought = self.think(input_content)
        
        # 3. ç”Ÿæˆå›å¤
        reply = f"åŸºäºåˆ†æï¼Œæˆ‘è®¤ä¸ºï¼š{input_content[:30]}... çš„æœ€ä½³å›åº”æ˜¯é€šè¿‡{thought['strategy']}æ¥å¤„ç†ã€‚"
        
        # 4. è¾“å‡ºéªŒè¯
        validation_status, validated_output = self.safety_manager.validate_agent_output(
            reply, self.name
        )
        
        if validation_status != ValidationStatus.VALID:
            console.print(f"âš ï¸ [yellow]è¾“å‡ºéªŒè¯çŠ¶æ€: {validation_status}[/yellow]")
        
        # è®°å½•ç”Ÿæˆçš„å›å¤
        log_conversation(
            agent_name=self.name,
            message=reply,
            role="assistant",
            metadata={
                "thought_process": thought,
                "safety_check": safety_result.flagged,
                "validation_status": validation_status.value
            }
        )
        
        return reply

class TracingWorkflowDemo:
    """Tracing å·¥ä½œæµæ¼”ç¤º"""
    
    def __init__(self):
        self.agents = {
            "researcher": TracingDemoAgent("å¸‚åœºç ”ç©¶å‘˜"),
            "analyst": TracingDemoAgent("æ•°æ®åˆ†æå¸ˆ"), 
            "writer": TracingDemoAgent("æŠ¥å‘Šæ’°å†™å‘˜")
        }
        
    @traced_agent_operation("workflow_execution")
    async def run_workflow(self, query: str) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å¤šAgentå·¥ä½œæµ"""
        console.print(Panel(f"ğŸš€ å¯åŠ¨å·¥ä½œæµ: {query}", style="blue"))
        
        workflow_results = {}
        
        # é˜¶æ®µ1ï¼šåˆå§‹åŒ–æ‰€æœ‰Agents
        console.print("\nğŸ“‹ [cyan]é˜¶æ®µ1: Agentåˆå§‹åŒ–[/cyan]")
        for agent_name, agent in self.agents.items():
            result = agent.initialize()
            workflow_results[f"{agent_name}_init"] = result
        
        # é˜¶æ®µ2ï¼šç ”ç©¶é˜¶æ®µ
        console.print("\nğŸ” [cyan]é˜¶æ®µ2: å¸‚åœºç ”ç©¶[/cyan]")
        research_messages = [{"role": "user", "content": f"è¯·ç ”ç©¶ä»¥ä¸‹ä¸»é¢˜: {query}"}]
        research_result = await self.agents["researcher"].generate_reply(
            research_messages, 
            {"phase": "research", "query": query}
        )
        workflow_results["research"] = research_result
        
        # é˜¶æ®µ3ï¼šæ•°æ®åˆ†æ
        console.print("\nğŸ“Š [cyan]é˜¶æ®µ3: æ•°æ®åˆ†æ[/cyan]")
        analysis_messages = [
            {"role": "user", "content": f"åŸºäºç ”ç©¶ç»“æœè¿›è¡Œæ•°æ®åˆ†æ: {research_result[:100]}..."}
        ]
        analysis_result = await self.agents["analyst"].generate_reply(
            analysis_messages,
            {"phase": "analysis", "research_input": research_result}
        )
        workflow_results["analysis"] = analysis_result
        
        # é˜¶æ®µ4ï¼šæŠ¥å‘Šæ’°å†™
        console.print("\nğŸ“ [cyan]é˜¶æ®µ4: æŠ¥å‘Šæ’°å†™[/cyan]")
        writing_messages = [
            {"role": "user", "content": f"æ’°å†™ç»¼åˆæŠ¥å‘Šï¼Œæ•´åˆç ”ç©¶å’Œåˆ†æç»“æœ"}
        ]
        final_report = await self.agents["writer"].generate_reply(
            writing_messages,
            {
                "phase": "writing", 
                "research_input": research_result,
                "analysis_input": analysis_result
            }
        )
        workflow_results["final_report"] = final_report
        
        return workflow_results

@traced_agent_operation("performance_monitoring")
def monitor_system_performance():
    """ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    metrics = {
        "timestamp": datetime.now().isoformat(),
        "system_load": "æ¨¡æ‹Ÿ: 65%",
        "memory_usage": "æ¨¡æ‹Ÿ: 2.1GB", 
        "active_agents": 3,
        "total_traces": "129",  # ä»æ‚¨çš„æˆªå›¾ä¸­çœ‹åˆ°çš„æ•°æ®
        "avg_latency": "7.63s",  # P50å»¶è¿Ÿ
        "p99_latency": "33.35s"  # P99å»¶è¿Ÿ
    }
    
    table = Table(title="ç³»ç»Ÿæ€§èƒ½ç›‘æ§")
    table.add_column("æŒ‡æ ‡", style="cyan")
    table.add_column("å½“å‰å€¼", style="green")
    
    for metric, value in metrics.items():
        table.add_row(metric, str(value))
    
    console.print(table)
    return metrics

@traced_agent_operation("trace_analysis")
def analyze_traces():
    """åˆ†æè¿½è¸ªæ•°æ®"""
    console.print(Panel("ğŸ” Trace æ•°æ®åˆ†æ", style="green"))
    
    # æ¨¡æ‹Ÿä»Phoenix UIè·å–çš„æ•°æ®
    trace_analysis = {
        "total_spans": 129,
        "span_types": {
            "agent_conversation": 45,
            "content_moderation": 23,
            "output_validation": 31,
            "agent_generate_reply": 18,
            "openai.chat": 8,
            "self_correction_loop": 4
        },
        "latency_distribution": {
            "< 1s": "65%",
            "1-5s": "25%", 
            "5-10s": "8%",
            "> 10s": "2%"
        },
        "error_rate": "0.7%",
        "success_rate": "99.3%"
    }
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    spans_table = Table(title="Span ç±»å‹åˆ†å¸ƒ")
    spans_table.add_column("Span ç±»å‹", style="cyan")
    spans_table.add_column("æ•°é‡", style="yellow")
    
    for span_type, count in trace_analysis["span_types"].items():
        spans_table.add_row(span_type, str(count))
    
    console.print(spans_table)
    
    latency_table = Table(title="å»¶è¿Ÿåˆ†å¸ƒ")
    latency_table.add_column("å»¶è¿ŸèŒƒå›´", style="cyan")
    latency_table.add_column("å æ¯”", style="green")
    
    for range_name, percentage in trace_analysis["latency_distribution"].items():
        latency_table.add_row(range_name, percentage)
    
    console.print(latency_table)
    
    return trace_analysis

async def main():
    """å®Œæ•´çš„ Tracing æ¼”ç¤º"""
    console.print("ğŸš€ [bold blue]Agent ç³»ç»Ÿ Tracing å®Œæ•´æ¼”ç¤º[/bold blue]\n")
    
    # 1. æ€§èƒ½ç›‘æ§
    monitor_system_performance()
    console.print()
    
    # 2. è¿è¡Œå·¥ä½œæµ
    demo = TracingWorkflowDemo()
    
    test_queries = [
        "åˆ†æäººå·¥æ™ºèƒ½è‚¡ç¥¨çš„æŠ•èµ„æœºä¼š",
        "è¯„ä¼°æ–°èƒ½æºæ±½è½¦å¸‚åœºå‰æ™¯"
    ]
    
    with Progress() as progress:
        task = progress.add_task("æ‰§è¡Œ Tracing å·¥ä½œæµ...", total=len(test_queries))
        
        for query in test_queries:
            console.print(f"\nğŸ¯ [bold yellow]å¤„ç†æŸ¥è¯¢: {query}[/bold yellow]")
            
            start_time = time.time()
            results = await demo.run_workflow(query)
            duration = time.time() - start_time
            
            console.print(f"âœ… [green]å·¥ä½œæµå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’[/green]")
            progress.update(task, advance=1)
    
    console.print()
    
    # 3. åˆ†æè¿½è¸ªæ•°æ®
    analyze_traces()
    
    # 4. æ˜¾ç¤ºPhoenix UIè®¿é—®ä¿¡æ¯
    phoenix_port = config.observability.phoenix_port
    console.print(Panel(
        f"ğŸŒ è®¿é—® Phoenix UI æŸ¥çœ‹è¯¦ç»†è¿½è¸ªæ•°æ®:\n\n"
        f"URL: http://localhost:{phoenix_port}\n"
        f"é¡µé¢: Traces -> æŸ¥çœ‹æœ€æ–°çš„ span æ•°æ®\n"
        f"ç­›é€‰: å¯ä»¥æŒ‰ span ç±»å‹ã€å»¶è¿Ÿã€æ—¶é—´èŒƒå›´ç­‰ç­›é€‰\n\n"
        f"ğŸ“Š å…³é”®æŒ‡æ ‡:\n"
        f"â€¢ Total Traces: æŸ¥çœ‹æ€»è¿½è¸ªæ•°é‡\n"
        f"â€¢ Latency P50/P99: ç›‘æ§å“åº”æ—¶é—´\n"
        f"â€¢ Error Rate: ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶æ€\n"
        f"â€¢ Span Details: æŸ¥çœ‹æ¯ä¸ªæ“ä½œçš„è¯¦ç»†ä¿¡æ¯",
        title="ğŸ” Phoenix UI ä½¿ç”¨æŒ‡å—",
        style="cyan"
    ))

if __name__ == "__main__":
    asyncio.run(main()) 